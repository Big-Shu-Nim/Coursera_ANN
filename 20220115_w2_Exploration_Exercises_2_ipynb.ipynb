{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "20220115_w2_Exploration Exercises_2~ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG1i7Z18eP2i",
        "outputId": "97abda6f-0506-415b-886e-1600a611458b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.4958 - accuracy: 0.8249\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3742 - accuracy: 0.8658\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3358 - accuracy: 0.8775\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3108 - accuracy: 0.8868\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2925 - accuracy: 0.8924\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3483 - accuracy: 0.8751\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3482837378978729, 0.8751000165939331]"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "fmnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = fmnist.load_data()\n",
        "\n",
        "training_images  = training_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)]) \n",
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy', \n",
        "              metrics=['accuracy'])  \n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        " \n",
        "model.evaluate(test_images, test_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Excersie 01\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpeDrgaeeUDZ",
        "outputId": "bab9489c-672e-43c9-d9ea-3809d7df0861"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4.7440020e-07 9.3751353e-09 3.4916616e-07 2.2885851e-08 1.4304109e-07\n",
            " 3.0938098e-02 1.6790290e-06 1.5034891e-02 5.3200852e-06 9.5401901e-01]\n",
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "E1Q2: How do you know that this list tells you that the item is an ankle boot?\n",
        "There's not enough information to answer that question\n",
        "The 10th element on the list is the biggest, and the ankle boot is labelled 9\n",
        "The ankle boot is label 9, and there are 0->9 elements in the list\n",
        "Click for Answer\n",
        "#### Answer The correct answer is (2). Both the list and the labels are 0 based, so the ankle boot having label 9 means that it is the 10th of the 10 classes. The list having the 10th element being the highest value means that the Neural Network has predicted that the item it is classifying is most likely an ankle boot"
      ],
      "metadata": {
        "id": "u-ikrn_-eetu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Exercise 2: Trying the model with 512 dense \n",
        "Question: What different results do you get for loss, training time etc? Why do you think that's the case?"
      ],
      "metadata": {
        "id": "2ZQj_XCsoXrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#My preussmed answer : \n",
        "I think the loss would be more decresed than the previous model(dense:128), yet the traning time would be incrased. \n",
        "\n",
        "It's becasue the computer now is going to calculate more cases; the more cases the computer do the math, the more accuracy it would get. \n",
        "\n",
        "However, doing so, It's going to take a more time than the previous model. \n"
      ],
      "metadata": {
        "id": "3g3Sg73relPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modeling with 512 dnese\n",
        "mnist= tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "traning_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)]) \n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss= 'sparse_categorical_crossentropy', # #It's a multi variables classifcaiton, so we need to measure how good or bad the result\n",
        "              metrics=['accuracy']) \n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classification = model.predict(test_images)\n",
        "print(classification[0])\n",
        "print(test_labels[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OtqV7CrgmTT",
        "outputId": "a149a0db-c235-4555-a7c1-d306579577bf"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 2.4541 - accuracy: 0.9057\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.3441 - accuracy: 0.9374\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.2992 - accuracy: 0.9410\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2574 - accuracy: 0.9463\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2431 - accuracy: 0.9508\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 2.2303 - accuracy: 0.1065\n",
            "[0.11855294 0.06995844 0.08232183 0.08719964 0.09738343 0.06451514\n",
            " 0.07100769 0.09256748 0.19712761 0.11936584]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# An Interpretation of the result before seeing the answer key\n",
        "The reulst was quite differnt than I expected. I assuemd loss would be down yet accrucy increased. But this was a half corrcted answer. This new model is too fit the traning data so that it's hard to predict test data sets:accuracy:0.10)\n",
        "I was surpised by the predictd value. I highl expcted to see label 9, but it has changed label 7. "
      ],
      "metadata": {
        "id": "vgrogwBckWxP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Terminology: The law of diminishing\n",
        "-The law of diminishing  marginal returns is a theory in economics that predicts that after some optimal level of capacity is reached, adding an additional factor of production will actually result in smaller increases in output."
      ],
      "metadata": {
        "id": "XDl2CmMvlCfu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The Answer Increase to 512 Neurons -- What's the impact?\n",
        "Training takes longer, but is more accurate\n",
        "Click for Answer\n",
        " by adding more Neurons we have to do more calculations, slowing down the process, \n",
        " but in this case they have a good impact -- we do get more accurate. \n",
        " That doesn't mean it's always a case of 'more is better', you can hit the law of diminishing returns very quickly!"
      ],
      "metadata": {
        "id": "qQmm-_9AiKxJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 3:\n",
        "#E3Q1: What would happen if you remove the Flatten() layer. Why do you think that's the case?"
      ],
      "metadata": {
        "id": "0NNXg0Zhp1LF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#My preussmed answer :\n",
        "I think this code will see an error. It's becasue the Flatten()layer has the information of input layers, if this were removed, how the model can conncted each other? "
      ],
      "metadata": {
        "id": "g_A2lruqqX8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modeling with  the condition of Ex03\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential(\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "id": "sz4T3kAGq3F5",
        "outputId": "aede4fbf-b2fa-4c4b-ac63-00b0b6522083"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-24-37c2bbf0687f>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\u001b[0m\n\u001b[0m                                                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Answer:\n",
        " You get an error about the shape of the data. It may seem vague right now, but it reinforces the rule of thumb tha**t the first layer in your network should be the same shape as your data.** Right now our data is **28x28 images, and 28 layers of 28 neurons **would be **infeasible**, so it makes more sense to 'flatten' that 28,28 into a 784x1. Instead of writng all the code to handle that ourselves, we add the Flatten() layer at the begining, and when the arrays are loaded into the model later, they'll automatically be flattened for us."
      ],
      "metadata": {
        "id": "-sIZRIrGsSpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 4:\n",
        "#Consider the final (output) layers. Why are there 10 of them? What would happen if you had a different amount than 10? For example, try training the network with 5."
      ],
      "metadata": {
        "id": "I7uvGm1Uxh6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#My Presuemd Answer for 04\n",
        "The reason why the finaly layers have 10 neuron is that the outcome we want to see is a classification of 10 diffrent classes. Thus, if I try it with diffrent amount of neuron like 5, I would get an error. "
      ],
      "metadata": {
        "id": "zl__KoI1xqzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Modeling for ex 04\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(64, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(5, activation=tf.nn.softmax) \n",
        "                                  ])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6VoUfUvjyRJg",
        "outputId": "e397b1c1-0927-426d-b974-925e56b6fbb6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-f19d3ce9fe24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m               loss = 'sparse_categorical_crossentropy')\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Received a label value of 9 which is outside the valid range of [0, 5).  Label values: 1 3 9 7 4 9 0 3 1 2 2 2 5 2 7 0 4 0 8 6 5 3 9 4 4 3 8 4 9 5 1 0\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits\n (defined at /usr/local/lib/python3.7/dist-packages/keras/backend.py:5114)\n]] [Op:__inference_train_function_115025]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:\nIn[0] sparse_categorical_crossentropy/Reshape_1 (defined at /usr/local/lib/python3.7/dist-packages/keras/backend.py:5109)\t\nIn[1] sparse_categorical_crossentropy/Reshape (defined at /usr/local/lib/python3.7/dist-packages/keras/backend.py:3561)\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n>>>     handler_func(fileobj, events)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n>>>     self._handle_recv()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n>>>     self._run_callback(callback, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n>>>     callback(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n>>>     return self.dispatch_shell(stream, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n>>>     handler(stream, idents, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n>>>     user_expressions, allow_stdin)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n>>>     if self.run_code(code, result):\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-25-f19d3ce9fe24>\", line 16, in <module>\n>>>     model.fit(training_images, training_labels, epochs=5)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 810, in train_step\n>>>     y, y_pred, sample_weight, regularization_losses=self.losses)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n>>>     loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 141, in __call__\n>>>     losses = call_fn(y_true, y_pred)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 245, in call\n>>>     return ag_fn(y_true, y_pred, **self._fn_kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1738, in sparse_categorical_crossentropy\n>>>     y_true, y_pred, from_logits=from_logits, axis=axis)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5114, in sparse_categorical_crossentropy\n>>>     labels=target, logits=output)\n>>> "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The answer for 04 :\n",
        " You get an error as soon as it finds an unexpected value. Another rule of thumb -- the number of neurons in the last layer should match **the number of classes you are classifying for.** In this case it's the digits 0-9, so there are 10 of them, hence you should have 10 neurons in your final layer."
      ],
      "metadata": {
        "id": "w03rH-GlyoM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vocabulary : rule of thumb\n",
        "a broadly accurate guide or principle, based on experience or practice rather than theory.\n",
        "\"a useful rule of thumb is that about ten hours will be needed to analyze each hour of recorded data\""
      ],
      "metadata": {
        "id": "zFI-Q7iNy0Py"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 5:\n",
        "#Consider the effects of additional layers in the network. What will happen if you add another layer between the one with 512 and the final layer with 10."
      ],
      "metadata": {
        "id": "q9jis941zM1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#My Presuemd Answer for 05\n",
        "-I guess we will see better accuracy yet take more time than the previous -model. I can't tell you the diffrerence between increasing the number of neuron and hidden layers.  "
      ],
      "metadata": {
        "id": "scutsTPLzTF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ex 05 run \n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, traing_labels) , (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models. Sequential([tf.keras.layers.Flatten(),\n",
        "                                     tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                     tf.keras.layers.Dense(256, activation=tf.nn.relu),\n",
        "                                     tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "model.compile(optimizer= 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications= model. predict(test_images)\n",
        "\n",
        "print(classifications[0])\n",
        "print(test_labels[0])\n",
        "                        "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD-srFX6z3EL",
        "outputId": "ea96bcdc-e986-434f-d710-3fc960b70a57"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2213 - accuracy: 0.9334\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0932 - accuracy: 0.9710\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0638 - accuracy: 0.9800\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.0495 - accuracy: 0.9843\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0400 - accuracy: 0.9868\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0746 - accuracy: 0.9770\n",
            "[1.52020885e-08 4.64060008e-07 1.04821379e-06 2.51632482e-05\n",
            " 1.15436249e-09 1.30051685e-08 7.79877551e-11 9.99967575e-01\n",
            " 1.42652237e-08 5.72398358e-06]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#An Interpretation of the result before seeing the answer key for 05\n",
        "Wow, I was amazed by the impact of additional layers. Although It takes more time yet it would also increse the accuracy of test accuracy(0.97) "
      ],
      "metadata": {
        "id": "0L5PQTqk2Duu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The  Answer for 05\n",
        " There isn't a significant impact -- because this is relatively simple data. For far more complex data (including color images to be classified as flowers that you'll see in the next lesson), extra layers are often necessary."
      ],
      "metadata": {
        "id": "xaiA01Ff2dUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 6:\n",
        "#E6Q1: Consider the impact of training for more or less epochs. Why do you think that would be the case?\n",
        "\n"
      ],
      "metadata": {
        "id": "Sjg5arFd2vTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#My Presuemd Answer for 06\n",
        "\n",
        "- The case for less epochs \n",
        "  - Training time would be decrased and the accuracy might be decreased too. \n",
        "- The case for more epohcs \n",
        "  - Training time would be incresed however, the accuracy might be incrased. I assuemd there is great possibility that the traning data would be overfit itself. "
      ],
      "metadata": {
        "id": "YlEiMJeN5-_E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy')\n",
        "\n",
        "model.fit(training_images, training_labels, epochs=5) # Experiment with the number of epochs\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "\n",
        "classifications = model.predict(test_images)\n",
        "\n",
        "print(classifications[34])\n",
        "print(test_labels[34])"
      ],
      "metadata": {
        "id": "cHb_G8pu6pjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ex 06 run , epochs= 3\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=3)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "classification= model.predict(test_images)\n",
        "print(classification[34])\n",
        "print(test_labels[34])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tv1J66Qd6uNh",
        "outputId": "0353dcc5-9684-4052-c81d-d1585850a0e7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2540 - accuracy: 0.9286\n",
            "Epoch 2/3\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1106 - accuracy: 0.9674\n",
            "Epoch 3/3\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0774 - accuracy: 0.9761\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0799 - accuracy: 0.9753\n",
            "[9.1724601e-08 3.9303447e-07 5.1200268e-04 9.4715628e-04 7.0269157e-10\n",
            " 1.2064137e-09 3.0867889e-10 9.9850595e-01 2.8795332e-05 5.7477964e-06]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ex 06 run , epochs= 10\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "classification= model.predict(test_images)\n",
        "print(classification[34])\n",
        "print(test_labels[34])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBaTU4OR8RBc",
        "outputId": "b5cead7e-f82d-4299-8d00-45e7d2766850"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2559 - accuracy: 0.9266\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1148 - accuracy: 0.9658\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0799 - accuracy: 0.9761\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0602 - accuracy: 0.9818\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0472 - accuracy: 0.9853\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0370 - accuracy: 0.9884\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0299 - accuracy: 0.9906\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0237 - accuracy: 0.9926\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0186 - accuracy: 0.9942\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0162 - accuracy: 0.9951\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0812 - accuracy: 0.9798\n",
            "[1.4250380e-15 2.8065353e-10 2.3722569e-08 5.4141998e-09 1.5506791e-17\n",
            " 1.5542221e-15 2.2540215e-18 1.0000000e+00 4.5785223e-10 1.3925682e-12]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ex 06 run , epochs= 30\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(training_images, training_labels) ,  (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(),\n",
        "                                    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.softmax)])\n",
        "model.compile(optimizer = 'adam',\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=30)\n",
        "\n",
        "model.evaluate(test_images, test_labels)\n",
        "classification= model.predict(test_images)\n",
        "print(classification[34])\n",
        "print(test_labels[34])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhiJd58K-C5M",
        "outputId": "bbda38e3-422d-41d2-f1c7-8438a26d51b1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2609 - accuracy: 0.9251\n",
            "Epoch 2/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1110 - accuracy: 0.9672\n",
            "Epoch 3/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0748 - accuracy: 0.9778\n",
            "Epoch 4/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0561 - accuracy: 0.9824\n",
            "Epoch 5/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0439 - accuracy: 0.9864\n",
            "Epoch 6/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0334 - accuracy: 0.9899\n",
            "Epoch 7/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0276 - accuracy: 0.9911\n",
            "Epoch 8/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0228 - accuracy: 0.9933\n",
            "Epoch 9/30\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.0185 - accuracy: 0.9945\n",
            "Epoch 10/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0153 - accuracy: 0.9953\n",
            "Epoch 11/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0130 - accuracy: 0.9961\n",
            "Epoch 12/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0117 - accuracy: 0.9961\n",
            "Epoch 13/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0087 - accuracy: 0.9974\n",
            "Epoch 14/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0087 - accuracy: 0.9972\n",
            "Epoch 15/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0072 - accuracy: 0.9979\n",
            "Epoch 16/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0079 - accuracy: 0.9975\n",
            "Epoch 17/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - accuracy: 0.9979\n",
            "Epoch 18/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - accuracy: 0.9980\n",
            "Epoch 19/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0057 - accuracy: 0.9982\n",
            "Epoch 20/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0045 - accuracy: 0.9985\n",
            "Epoch 21/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0066 - accuracy: 0.9979\n",
            "Epoch 22/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0038 - accuracy: 0.9988\n",
            "Epoch 23/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0057 - accuracy: 0.9982\n",
            "Epoch 24/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0044 - accuracy: 0.9987\n",
            "Epoch 25/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0049 - accuracy: 0.9983\n",
            "Epoch 26/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0031 - accuracy: 0.9990\n",
            "Epoch 27/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0058 - accuracy: 0.9980\n",
            "Epoch 28/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0030 - accuracy: 0.9991\n",
            "Epoch 29/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0038 - accuracy: 0.9986\n",
            "Epoch 30/30\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0035 - accuracy: 0.9988\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.1154 - accuracy: 0.9802\n",
            "[1.04056536e-23 6.22610476e-22 5.08888938e-12 1.23539109e-15\n",
            " 8.06992888e-33 3.09894586e-29 4.98129555e-30 1.00000000e+00\n",
            " 1.46448741e-20 7.70036033e-23]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The answer for 06 :\n",
        "Try 10 epochs -- you'll probably get a model with a much better loss than the one with 5\n",
        "Try 30 epochs -- you might see the loss value stops decreasing, and sometimes increases.\n",
        "This is a side effect of something called 'overfitting' which you can learn about later and it's something you need to keep an eye out for when training neural networks. There's no point in wasting your time training if you aren't improving your loss, right! :)"
      ],
      "metadata": {
        "id": "wXD6Jy5V-TLV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 7:\n",
        "#Before you trained, you normalized the data, going from values that were 0-255 to values that were 0-1. What would be the impact of removing that? Why do you think you get different results?"
      ],
      "metadata": {
        "id": "nyBIG1RL-dJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# My presuemd Answer for 07:\n",
        "I had no idea about this question. In a vauge awareness, I assuemd that the metrics of each data should be same; doing so the computer accrutely compute the each process."
      ],
      "metadata": {
        "id": "8R7XBDyo-ml7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Run model ex 07: Removed the normalized data \n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyv-M6Tc_Oa1",
        "outputId": "523724ed-576a-4fb0-8266-7a5dd00b4057"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 4ms/step - loss: 2.7318\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 8s 5ms/step - loss: 0.3313\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2870\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2787\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2412\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.3383\n",
            "[0.0000000e+00 4.5206367e-28 7.9875078e-19 5.2232134e-18 1.0137193e-30\n",
            " 3.5409979e-29 0.0000000e+00 1.0000000e+00 3.5727987e-31 3.2150695e-18]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run model ex 07: Bring back the normalized data\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "training_images = training_images/255.0\n",
        "test_images = test_images/255.0\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "model.evaluate(test_images, test_labels)\n",
        "classifications = model.predict(test_images)\n",
        "print(classifications[0])\n",
        "print(test_labels[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_40S3YQYAdxe",
        "outputId": "c5b1f0ef-6a67-438e-9f5b-cabe3a45432a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2012\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0795\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0528\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0379\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0276\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0809\n",
            "[2.6507196e-09 1.4524129e-10 1.2384319e-07 1.9545352e-05 4.5953953e-14\n",
            " 1.1344330e-10 1.9074606e-14 9.9998033e-01 2.2071041e-10 3.1898328e-08]\n",
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#An interprecation for ex 07 before seeing the answer \n",
        "I would see great difference in the rate of loss. The normalized data would see \n",
        "better result than the raw data. "
      ],
      "metadata": {
        "id": "cP6hlIouA8pH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Answer 07:\n"
      ],
      "metadata": {
        "id": "alG3MPErBOUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exercise 8:\n",
        "Earlier when you trained for extra epochs you had an issue where your loss might change. It might have taken a bit of time for you to wait for the training to do that, and you might have thought .\n",
        "#'wouldn't it be nice if I could stop the training when I reach a desired value?' \n",
        "-- i.e. 95% accuracy might be enough for you, and if you reach that after 3 epochs, why sit around waiting for it to finish a lot more epochs....So how would you fix that? Like any other program...you have callbacks! Let's see them in action..."
      ],
      "metadata": {
        "id": "JtC1JEn6BUhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#call back >= 0.6 \n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') >= 0.6): # Experiment with changing this value\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5, callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBnljefTBsYh",
        "outputId": "e1b6b75c-e5eb-4f6b-ccfa-d3cf3b42d852"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.4728 - accuracy: 0.8306\n",
            "Reached 60% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4727 - accuracy: 0.8306\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6bec44ab10>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#call back >= 0.9, epochs=15 \n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy') >= 0.9): # Experiment with changing this value\n",
        "      print(\"\\nReached 60% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images/255.0\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=15, callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGNI5RwGB99D",
        "outputId": "2fc5be9b-d596-4b19-e1fe-4e1325e6ff02"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.4743 - accuracy: 0.8295\n",
            "Epoch 2/15\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3581 - accuracy: 0.8679\n",
            "Epoch 3/15\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3205 - accuracy: 0.8823\n",
            "Epoch 4/15\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2990 - accuracy: 0.8880\n",
            "Epoch 5/15\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.2801 - accuracy: 0.8969\n",
            "Epoch 6/15\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.2654 - accuracy: 0.9003\n",
            "Reached 60% accuracy so cancelling training!\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2654 - accuracy: 0.9003\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6bec461b90>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    }
  ]
}